#+title: yale linear regression
#+ROAM_TAGS: math statistics
#+ROAM_KEY: http://www.stat.yale.edu/Courses/1997-98/101/linreg.htm

* [[file:20210611165147-linear_regression.org][Linear regression]]
  attempts to model the relationship between two variables by
  fitting [[file:20210527195050-linear_equation.org][linear equation]] to observed data.
  One variable is an explanatory variable, and the other is a dependent variable
** Example
   Relate the weights of individuals to their heights
** there should be a relationship between the variables of interest
*** does not need to be a causal relation
**** example
     higher SAT scores do not cause higher college grades
*** There must be significant association between the two variables
*** [[file:20210527195359-scatterplots.org][scatterplots]] can help determine the strength of the relationship between the two variables
**** must indicate increasing or decreasing trends
*** correlation coefficient can help
    This is a numerical measure of association between two variables.
    It's value between -1 and 1 indicating the strength of the association of the observed
    data for the two variables..
** Equation
   A linear regression line has an equation of the form
   Y = a + bX

   X is the explanatory variable
   Y is the dependent variable
   b is the slope of the line
   a is the intercept (the value of y when x = 0)

* Least-Squares regression
** most common method for fitting a regression line
** calculates the best-fitting line for the observed data
   Does so by minimizing the sum of the squares of the vertical deviations from each data
   point to the line.
   If a point lies on the fitted line exactly, then its vertical deviation is 0.
   Because deviatiosn are first squared and then summed, there are no cancellations between
   positive and negative values.
** Example
*** Dataset: Televisions, Physicians, Life Expectancy
    Contains, for 40 countries:
      Number of people per television set
      Number of people per physician

    Both variables probably reflect the level of wealth in each country
      Therefore, it's reasonable to assume that there is some positive
      association between them.

    Remove 8 countries with missing values from the dataset (why does this matter lol)
    Remaining 32 countries have a correlation coefficient of 0.852 for number of people per
    television set and number of people per physician.

    The r^2 value is 0.726
      This is the square of the correlation coefficient.
      This indicates that 72.6% of the variation in one variable may be explained by the other
        I guess this is explained in correlation: http://www.stat.yale.edu/Courses/1997-98/101/correl.htm
      Taking the number of people per television as the explanatory variable,
      and the number of people per physician as the dependent variable:
        Use the MINITAB "REGRESS" command:
          The regression equation is People.Phys. = 1019 + 56.2 People.Tel.
**** plotting
     You can view the fit of the model to the observed data
     Plot the computed regression line over the actual data points to evaluate the results
     See below,
       x: explanatory variable: number of individuals per television set
       y: dependent variable: number of individuals per physician

       Most of the data points are clustered on the lower left corner of the screen
         This indicates relatively few individual per television set and per physician

       There are a few points which lie far away from the main cluster of the data.
         These are called [[file:20210528140606-outliers.org][outliers]]
         Depending on their location may have a major impact on the regression line.

       [[./leastsquaresregressionline.gif]]

* [[file:20210528140606-outliers.org][Outliers]] and [[file:20210528140839-influential_observations.org][Influential Observations]]
  A point which lies far from the line and has a large residual value is known as an outlier.
  You see this after you compute a regression line.

** Potential causes
*** Erroneous data
*** Poorly fitting regression line
** [[file:20210528140839-influential_observations.org][Influential Observation]]
   When a point lies far from other data in the horizontal direction.
   Such points may have a significant impact on the [[file:20210602150349-slope.org][slope]] of the [[file:20210527205331-regression_line.org][regression line]].

   In the above example, there is an influential observation.
   If it's removed, the equation becomes

\begin{equation}
People.Phys = 1650 + 21.3 People.Tel.
\end{equation}

  And I guess looks like this:

[[./lsline2.gif]]

  The correlation between the two variables has dropped to .0427
  Thus the r^2 value is reduced to 0.182
  Thus, less than 20% of the variation in number of people per physicians may be explained by
  the number of people per TV.
  Note that there are still influential observations in the new model. Their investigation should be investigated.

* [[file:20210602160647-residuals.org][Residuals]]
  Residuals are deviations from the fitted line to the observed values
** Examining residuals allows modeler to investigate the validity of the assumption that a linear relationship exists
   Plotting the residuals on the y-axis against the explanatory variable on the x-axis reveals any possible non-linear relatioship
   among the variables
   Or it might indicate [[file:20210602160826-lurking_variables.org][lurking variables]]
   See below, a residual plot amplifies the presence of outliers
  [[./lsresid.gif]]

** [[file:20210602160826-lurking_variables.org][Lurking Variables]]
   A third variable, not included in the modeling effort,
   that significantly affects the relationship between two variables
   Worth considering as relevant if non-linear trends are visible in the relationship between an explanatory
   and dependent variable.

*** May be a factor of time
    FOr example, the effect of political or economic cycles
**** Thus a [[file:20210602161127-time_series_plot.org][time series plot]] of the data is useful in identifying the presence of [[file:20210602160826-lurking_variables.org][lurking variables]]

* [[file:20210602161145-extrapolation.org][Extrapolation]]
  is when Attempting to use a regression equation to predict values outside the range of the data,
  which is inappropriate and may yield "incredible" answers.
  Consider a linear model which relates weight gain to age for young children.
    Applying such a model to adults would be absurd, because the relationship between
    age and weight gain is not consistent for all age groups.
